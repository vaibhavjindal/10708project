{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDybSNohHPav"
   },
   "source": [
    "This is an implementation of the paper Deep Bayesian Active Learning with Image Data using PyTorch and modAL. \n",
    "\n",
    "modAL is an active learning framework for Python3, designed with modularity, flexibility and extensibility in mind. Built on top of scikit-learn, it allows you to rapidly create active learning workflows with nearly complete freedom. What is more, you can easily replace parts with your custom built solutions, allowing you to design novel algorithms with ease.\n",
    "\n",
    "Since modAL only supports sklearn models, we will also use [skorch](https://skorch.readthedocs.io/en/stable/), a scikit-learn compatible neural network library that wraps PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqMvkeW0H_lH"
   },
   "outputs": [],
   "source": [
    "PATH = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faKF-oErI4qM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWek67dkHPa1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import MNIST\n",
    "from skorch import NeuralNetClassifier\n",
    "from modAL.models import ActiveLearner\n",
    "\n",
    "# from VAE import VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpvD-4jLHPa4"
   },
   "source": [
    "### architecture of the network we will be using\n",
    "\n",
    "We will use the architecture described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([0.1307], dtype=torch.float32)\n",
    "std = torch.tensor([0.3081], dtype=torch.float32)\n",
    "\n",
    "normalize = transforms.Normalize(mean.tolist(), std.tolist())\n",
    "unnormalize = transforms.Normalize((-mean / std).tolist(), (1.0 / std).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXs5ukM9HPa5"
   },
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self,):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.convs = nn.Sequential(\n",
    "#                                 nn.Conv2d(1,32,4),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Conv2d(32,32,4),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.MaxPool2d(2),\n",
    "#                                 nn.Dropout(0.25)\n",
    "#         )\n",
    "#         self.fcs = nn.Sequential(\n",
    "#                                 nn.Linear(11*11*32,128),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Dropout(0.5),\n",
    "#                                 nn.Linear(128,10),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = x\n",
    "#         out = self.convs(out)\n",
    "#         out = out.view(-1,11*11*32)\n",
    "#         out = self.fcs(out)\n",
    "#         return out\n",
    "input_dim, input_height, input_width = 1, 28, 28\n",
    "class lenet(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(lenet, self).__init__()\n",
    "        self.input_height = input_height\n",
    "        self.input_width = input_width\n",
    "        self.input_dim = input_dim\n",
    "        self.class_num = 10\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.input_dim, 6, (5, 5), padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5, 5))\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, self.class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rktp-otJHPa6"
   },
   "source": [
    "### read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEqKpWdTHPa7"
   },
   "outputs": [],
   "source": [
    "mnist_train = MNIST(PATH, train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "mnist_test  = MNIST(PATH, train=False,download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "traindataloader = DataLoader(mnist_train, shuffle=True, batch_size=60000)\n",
    "testdataloader  = DataLoader(mnist_test , shuffle=True, batch_size=10000)\n",
    "X_train, y_train = next(iter(traindataloader))\n",
    "X_test , y_test  = next(iter(testdataloader))\n",
    "X_train, y_train = X_train.detach().cpu().numpy(), y_train.detach().cpu().numpy()\n",
    "X_test, y_test = X_test.detach().cpu().numpy(), y_test.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYzXhY7tHPa8"
   },
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnkcSDVLHPa8"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 1, 28, 28)\n",
    "X_test = X_test.reshape(10000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i5xaHXYHPa9"
   },
   "source": [
    "### initial labelled data\n",
    "We initialize the labelled set with 100 balanced randomly sampled examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiPu-s7cHPa-"
   },
   "outputs": [],
   "source": [
    "initial_idx = np.array([],dtype=int)\n",
    "for i in range(10):\n",
    "    idx = np.random.choice(np.where(y_train==i)[0], size=10, replace=False)\n",
    "    initial_idx = np.concatenate((initial_idx, idx))\n",
    "\n",
    "X_initial = X_train[initial_idx]\n",
    "y_initial = y_train[initial_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epivtRwoHPa-"
   },
   "source": [
    "### initial unlabelled pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Om2D3c2tHPa_"
   },
   "outputs": [],
   "source": [
    "# X_pool = np.delete(X_train, initial_idx, axis=0)\n",
    "# y_pool = np.delete(y_train, initial_idx, axis=0)\n",
    "\n",
    "X_pool = np.copy(X_train)\n",
    "y_pool = np.copy(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBlEorZUHPa_"
   },
   "source": [
    "## Query Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSPdemp1HPa_"
   },
   "source": [
    "### Uniform\n",
    "All the acquisition function we will use will be compared to the uniform acquisition function $\\mathbb{U}_{[0,1]}$ which will be our baseline that we would like to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccRpmpz0HPbA"
   },
   "outputs": [],
   "source": [
    "def uniform(learner, X, n_instances=1):\n",
    "    query_idx = np.random.choice(range(len(X)), size=n_instances, replace=False)\n",
    "    return query_idx, X[query_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgktR50MHPbA"
   },
   "source": [
    "### Entropy\n",
    "Our first acquisition function is the entropy:\n",
    "$$ \\mathbb{H} = - \\sum_{c} p_c \\log(p_c)$$\n",
    "where $p_c$ is the probability predicted for class c. This is approximated by:\n",
    "\\begin{align}\n",
    "p_c &= \\frac{1}{T} \\sum_t p_{c}^{(t)} \n",
    "\\end{align}\n",
    "where $p_{c}^{t}$ is the probability predicted for class c at the t th feedforward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sASPJJn2HPbB"
   },
   "outputs": [],
   "source": [
    "def max_entropy(learner, X, n_instances=1, T=100):\n",
    "    random_subset = np.random.choice(range(len(X)), size=2000, replace=False)\n",
    "    with torch.no_grad():\n",
    "        outputs = np.stack([torch.softmax(learner.estimator.forward(X[random_subset], training=True),dim=-1).cpu().numpy()\n",
    "                            for t in range(20)])\n",
    "    pc = outputs.mean(axis=0)\n",
    "    acquisition = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    idx = (-acquisition).argsort()[:n_instances]\n",
    "    query_idx = random_subset[idx]\n",
    "    return query_idx, X[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfjFuNvBHPbB"
   },
   "outputs": [],
   "source": [
    "def bald(learner, X, n_instances=1, T=100):\n",
    "    random_subset = np.random.choice(range(len(X)), size=2000, replace=False)\n",
    "    with torch.no_grad():\n",
    "        outputs = np.stack([torch.softmax(learner.estimator.forward(X[random_subset], training=True),dim=-1).cpu().numpy()\n",
    "                            for t in range(20)])\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0)  # [batch size]\n",
    "    acquisition = H - E_H\n",
    "    idx = (-acquisition).argsort()[:n_instances]\n",
    "    query_idx = random_subset[idx]\n",
    "    return query_idx, X[query_idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHd2s8XbHPbC"
   },
   "outputs": [],
   "source": [
    "os.makedirs(f\"{PATH}/perf_lists_vae/\",exist_ok=True)\n",
    "def save_list(input_list, name):\n",
    "    with open(f\"{PATH}/perf_lists_vae/\" + name, 'w') as f:\n",
    "        for val in input_list:\n",
    "            f.write(\"%s\\n\" % val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk40YbwoHPbC"
   },
   "source": [
    "### Active Learning Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttyhd02qHPbC"
   },
   "outputs": [],
   "source": [
    "def active_learning_procedure_vae(query_strategy,\n",
    "                              X_test,\n",
    "                              y_test,\n",
    "                              X_pool,\n",
    "                              y_pool,\n",
    "                              X_initial,\n",
    "                              y_initial,\n",
    "                              estimator,\n",
    "                              n_queries=150,\n",
    "                              n_instances=10):\n",
    "    weights_location = f'{PATH}/weights.pt'\n",
    "    vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "    vae.load_state_dict(torch.load(weights_location))\n",
    "\n",
    "    def vaeNewSampleGenerator(vae, samples):    \n",
    "        vae.eval()\n",
    "        with torch.no_grad():\n",
    "            new_samples, _, _ = vae(samples.reshape(samples.shape[0], -1))\n",
    "            return new_samples.reshape(samples.shape)\n",
    "\n",
    "    learner = ActiveLearner(estimator=estimator,\n",
    "                            X_training=X_initial,\n",
    "                            y_training=y_initial,\n",
    "                            query_strategy=query_strategy,\n",
    "                           )\n",
    "    perf_hist = [learner.score(X_test, y_test)]\n",
    "    X_rolling, y_rolling = np.copy(X_initial), np.copy(y_initial)\n",
    "    for index in range(n_queries):\n",
    "        query_idx, query_instance = learner.query(X_pool, n_instances)\n",
    "        \n",
    "#         new_samples = vaeNewSampleGenerator(vae, unnormalize(torch.tensor(X_pool[query_idx])).to(torch.device(\"cuda\")))\n",
    "        new_samples = vaeNewSampleGenerator(vae, unnormalize(torch.tensor(X_pool[query_idx])))\n",
    "        new_samples = normalize(new_samples)\n",
    "        new_samples = new_samples.detach().cpu().numpy()\n",
    "        new_samples = np.concatenate((new_samples, X_pool[query_idx]))\n",
    "        new_labels = np.concatenate((y_pool[query_idx], y_pool[query_idx]))\n",
    "        \n",
    "        X_rolling, y_rolling = np.concatenate((X_rolling, new_samples), axis=0), np.concatenate((y_rolling, new_labels))\n",
    "        learner.fit(X_rolling, y_rolling)\n",
    "        \n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
    "        model_accuracy = learner.score(X_test, y_test)\n",
    "        print('Accuracy after query {n}: {acc:0.4f}'.format(n=index + 1, acc=model_accuracy))\n",
    "        perf_hist.append(model_accuracy)\n",
    "    return perf_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6291404,
     "status": "ok",
     "timestamp": 1651122505744,
     "user": {
      "displayName": "Sankalp Garg",
      "userId": "15572589619349752921"
     },
     "user_tz": 240
    },
    "id": "9lykJv15HPbD",
    "outputId": "012ab1d4-0ff6-4116-f3e4-417434d423bc"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "estimator = NeuralNetClassifier(lenet,\n",
    "                                max_epochs=50,\n",
    "                                batch_size=100,\n",
    "                                lr=1.0,\n",
    "                                optimizer=torch.optim.Adadelta,\n",
    "                                optimizer__rho=0.9,\n",
    "                                optimizer__eps=1e-6,\n",
    "                                criterion=torch.nn.CrossEntropyLoss,\n",
    "                                train_split=None,\n",
    "                                verbose=0,\n",
    "                                device=device)\n",
    "bald_vae_perf_hist = active_learning_procedure_vae(bald,\n",
    "                                           X_test,\n",
    "                                           y_test,\n",
    "                                           X_pool,\n",
    "                                           y_pool,\n",
    "                                           X_initial,\n",
    "                                           y_initial,\n",
    "                                           estimator,\n",
    "                                            n_instances=100)\n",
    "save_list(bald_vae_perf_hist, \"bald_vae_perf_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6261302,
     "status": "ok",
     "timestamp": 1651128942869,
     "user": {
      "displayName": "Sankalp Garg",
      "userId": "15572589619349752921"
     },
     "user_tz": 240
    },
    "id": "jcRVc806HPbD",
    "outputId": "87c0abc7-ec33-4f58-b0e9-20774fc5c585"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "estimator = NeuralNetClassifier(lenet,\n",
    "                                max_epochs=50,\n",
    "                                batch_size=100,\n",
    "                                lr=1.0,\n",
    "                                optimizer=torch.optim.Adadelta,\n",
    "                                optimizer__rho=0.9,\n",
    "                                optimizer__eps=1e-6,\n",
    "                                criterion=torch.nn.CrossEntropyLoss,\n",
    "                                train_split=None,\n",
    "                                verbose=0,\n",
    "                                device=device)\n",
    "entropy_vae_perf_hist = active_learning_procedure_vae(max_entropy,\n",
    "                                           X_test,\n",
    "                                           y_test,\n",
    "                                           X_pool,\n",
    "                                           y_pool,\n",
    "                                           X_initial,\n",
    "                                           y_initial,\n",
    "                                           estimator,\n",
    "                                            n_instances=100)\n",
    "save_list(entropy_vae_perf_hist, \"entropy_vae_perf_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7379066,
     "status": "ok",
     "timestamp": 1651172336958,
     "user": {
      "displayName": "Sankalp Garg",
      "userId": "15572589619349752921"
     },
     "user_tz": 240
    },
    "id": "_VpFs9IwHPbE",
    "outputId": "43366c0c-f75e-4973-ab41-6a8a1122b1ec"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "estimator = NeuralNetClassifier(lenet,\n",
    "                                max_epochs=50,\n",
    "                                batch_size=100,\n",
    "                                lr=1.0,\n",
    "                                optimizer=torch.optim.Adadelta,\n",
    "                                optimizer__rho=0.9,\n",
    "                                optimizer__eps=1e-6,\n",
    "                                criterion=torch.nn.CrossEntropyLoss,\n",
    "                                train_split=None,\n",
    "                                verbose=0,\n",
    "                                device=device)\n",
    "uniform_vae_perf_hist = active_learning_procedure_vae(uniform,\n",
    "                                           X_test,\n",
    "                                           y_test,\n",
    "                                           X_pool,\n",
    "                                           y_pool,\n",
    "                                           X_initial,\n",
    "                                           y_initial,\n",
    "                                           estimator,\n",
    "                                            n_instances=100)\n",
    "save_list(uniform_vae_perf_hist, \"uniform_vae_perf_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clGSK2AQMeCJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dbal_pytorch_vae.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p38)",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
